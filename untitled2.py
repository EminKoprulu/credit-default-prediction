# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q9u1G_2dTOKHSBZFFRJ1mhcfWRP5S4y0

Veri Setindeki Amaç

Bu projede amaç, bireylerin kredi kartı temerrüt (ödeyememe) durumlarını tahmin etmek için çeşitli sınıflandırma algoritmalarının performanslarını karşılaştırmaktır. Kullanılacak algoritmaların başarısı; doğruluk oranı (accuracy), sınıflandırma başarısı ve karışıklık matrisi (confusion matrix) gibi metrikler üzerinden değerlendirilecektir.



Veri Seti Kaynağı: Kaggle: Default of Credit Card Clients Dataset
Satır (Gözlem) Sayısı: 30.000
Sütun (Özellik) Sayısı: 23
Hedef Değişken (Target): default.payment.next.month (0: Temerrüde düşmedi, 1: Temerrüde düştü)



Veri Setinin Açıklaması
Bu veri seti, Tayvan’daki bir bankaya ait kredi kartı kullanıcılarının geçmiş bilgilerini ve ödeme alışkanlıklarını içermektedir. Banka, kullanıcıların bir sonraki ay temerrüde düşüp düşmeyeceğini tahmin etmek için bu bilgileri kullanmaktadır. Bu sebeple veri seti, sınıflandırma algoritmalarının eğitimi için uygun bir örnek teşkil etmektedir.



Özelliklerin Detaylı Açıklaması:

LIMIT_BAL |	Kredi kartı limiti (TWD biriminde)

SEX	| Cinsiyet (1=Erkek, 2=Kadın)

EDUCATION	| Eğitim durumu (1=Mezuniyet, 2=Üniversite, 3=Lise, 4=Diğer)

MARRIAGE |	Medeni durum (1=Evli, 2=Bekar, 3=Diğer)

AGE |	Yaş

PAY_0, PAY_2, ... |	Önceki 6 aya ait ödeme durumları (geri ödeme olup olmadığı)

BILL_AMT1 ~ BILL_AMT6 | 6 ay boyunca fatura tutarları

PAY_AMT1 ~ PAY_AMT6	| 6 ay boyunca yapılan ödeme tutarları

default.payment.next.month	| Hedef değişken – Kişi ödemeyi yapmış mı (0) yoksa yapmamış mı (1)



Neden Bu Veri Seti Seçildi?
Gerçek banka verileri içerdiği için yüksek doğrulukla model eğitimi yapılabilir.

Öznitelik sayısı yüksek olduğu için veri ön işleme ve modelleme tekniklerinin uygulaması açısından zengindir.

Veri dengesi (sınıfların dağılımı), sınıflandırma algoritmalarının başarılarını karşılaştırmak için uygundur.

Kaggle'dan erişilebilir durumdadır.

## Veri Setini Tanıtma:
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
import lightgbm as lgb
from lightgbm import LGBMClassifier
from sklearn.metrics import classification_report, confusion_matrix


df = pd.read_csv("UCI_Credit_Card.csv")

# Veri setinin ilk 5 satırını görüntüle
print("Veri setinin ilk 5 satırı:")
print(df.head())

# Veri setinin boyutunu görüntüle (satır ve sütun sayısı)
print("\nVeri setinin boyutu (satır, sütun):")
print(df.shape)

# Sütun isimlerini listele
print("\nSütun isimleri:")
print(df.columns.tolist())

# Hedef değişkenin (default.payment.next.month) sınıf dağılımını göster
print("\nHedef değişkenin sınıf dağılımı:")
print(df["default.payment.next.month"].value_counts())

# Eksik değer olup olmadığını kontrol et
print("\nEksik değer sayısı (her sütun için):")
print(df.isnull().sum())

# Temel istatistiksel özetleri al (sayısal değişkenler için)
print("\nTemel istatistiksel özet:")
print(df.describe())

"""## Veri Setini Temizleme:"""

### 1. DENGESİZ VERİ KONTROLÜ ###
# Hedef değişkenin (default.payment.next.month) dağılımına bakıyoruz
print("\nSınıf dağılımı:")
print(df["default.payment.next.month"].value_counts())

# Sınıf dağılımını görselleştir
sns.countplot(x="default.payment.next.month", data=df)
plt.title("Hedef Değişkenin (default.payment.next.month) Sınıf Dağılımı")
plt.xlabel("Temerrüt Durumu (0=Yok, 1=Var)")
plt.ylabel("Kişi Sayısı")
plt.show()


### 2. OUTLIER (AYKIRI DEĞER) KONTROLÜ ###
# Sayısal sütunlar üzerinden boxplot çizerek aykırı değerleri görelim
sayisal_sutunlar = df.select_dtypes(include=["int64", "float64"]).columns

# Her özellik için boxplot (ilk 6'sı örnek olarak çizilir)
plt.figure(figsize=(15, 10))
for i, col in enumerate(sayisal_sutunlar[:6]):
    plt.subplot(2, 3, i+1)
    sns.boxplot(y=df[col])
    plt.title(f"{col} Boxplot")
plt.tight_layout()
plt.show()

"""Hedef değişken olan default.payment.next.month değişkenine ait sınıf dağılımı grafiği incelendiğinde, temerrüde düşmeyen (0) bireylerin sayısının 23.364, temerrüde düşen (1) bireylerin sayısının ise 6.636 olduğu görülmektedir. Bu durum veri setinde bir miktar sınıf dengesizliği olduğunu göstermektedir. Yani, borcunu ödemeyen bireylerin sayısı ödeyenlere göre daha azdır. Ancak bu fark çok uç düzeyde olmadığı için sınıflandırma algoritmaları bu dağılımla baş edebilir. Yine de modelleme sürecinde sınıf ağırlıkları dikkatli ayarlanmalı veya gerekiyorsa SMOTE gibi veri dengeleme yöntemleri kullanılmalıdır.

LIMIT_BAL değişkenine ait boxplot incelendiğinde, kredi kartı limitleri arasında büyük farklılıklar olduğu ve üst sınırda birçok aykırı değerin bulunduğu gözlemlenmektedir. Özellikle bazı bireylerin limitlerinin 1 milyon TWD’ye kadar çıkması, bu kişilerin normal popülasyondan farklı finansal profillere sahip olduklarını göstermektedir. Bu tarz uç değerler finansal veri setlerinde olağan kabul edilebilir ve doğrudan veri dışı bırakılması yerine ölçeklendirme (scaling) ya da log dönüşümü gibi yöntemlerle modele dahil edilmesi önerilir.

AGE değişkeni için çizilen boxplot’ta da aykırı değerler mevcuttur. Yaş değeri 60’ın üzerine çıkan bireylerin kutunun dışında konumlandığı ve istatistiksel olarak aykırı kabul edildiği görülmektedir. Ancak yaş verisi doğası gereği geniş bir aralıkta dağıldığı için, bu değerler gerçek bireyleri temsil ettiğinden silinmesi yerine dikkatli şekilde modele dahil edilmelidir. Genel olarak yaş değişkeni, kredi ödeme davranışlarıyla doğrudan ilişkili olabileceği için, analizlerde önemli bir rol oynayabilir.

EDUCATION değişkenine ait boxplot grafiğinde ise veri sözlüğünde tanımlı olmayan 0, 5 ve 6 gibi değerlerin bulunduğu görülmektedir. Bu da veri setinde bazı kodlama hataları ya da eksik bilgi kategorilerinin olduğunu düşündürmektedir. Normalde eğitim düzeyleri 1 (lisansüstü), 2 (üniversite), 3 (lise) ve 4 (diğer) gibi tanımlanmışken, bu değerlerin varlığı veri ön işleme aşamasında ele alınmalıdır. Bu tür veriler, "bilinmiyor" ya da "diğer" şeklinde yeniden sınıflandırılarak düzeltilmelidir.

MARRIAGE değişkenine ait boxplot grafiği de benzer bir sorunu yansıtmaktadır. Normalde evli (1), bekar (2) ve diğer (3) gibi değerler içermesi gereken bu sütunda 0 değeri de yer almaktadır. 0 değeri büyük ihtimalle eksik veya yanlış veri girişinden kaynaklanmaktadır. Bu değerler de veri ön işleme aşamasında uygun şekilde yeniden sınıflandırılmalı ya da analiz dışında bırakılmalıdır. Çünkü kategorik değişkenlerde tanımsız değerler modelin performansını olumsuz etkileyebilir.

Son olarak, SEX ve ID değişkenlerine ait boxplot'larda teknik olarak aykırı değer görünmese de bu sütunlar modelleme açısından dikkatli değerlendirilmelidir. SEX sütunu zaten sadece 1 ve 2 değerleri (erkek/kadın) içerdiğinden dolayı boxplot grafik olarak anlamlı bir çıkarım sunmaz. ID değişkeni ise her birey için benzersiz bir numara olduğu için modelde kullanılmamalıdır. Bu tür tanımlayıcı alanlar sadece indeksleme amacıyla kullanılır ve doğrudan analizde yer almaz.
"""

# ID sütunu modellemeye dahil edilmemeli, bu yüzden kaldıralım
df.drop("ID", axis=1, inplace=True)

# Bağımsız değişkenler (X) ve hedef değişken (y) olarak ayır
X = df.drop("default.payment.next.month", axis=1)
y = df["default.payment.next.month"]

# Veriyi eğitim (%80) ve test (%20) olarak ayır
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Sayısal verileri ölçeklendirme (özellikle KNN ve MLP için önemli)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Sonuçları tutmak için fonksiyon
def evaluate_model(name, y_true, y_pred):
    print(f"\n=== {name} ===")
    print("Confusion Matrix:")
    print(confusion_matrix(y_true, y_pred))
    print("\nClassification Report:")
    print(classification_report(y_true, y_pred))

### 1. Logistic Regression ###
logreg = LogisticRegression(max_iter=1000)
logreg.fit(X_train_scaled, y_train)
y_pred_logreg = logreg.predict(X_test_scaled)
evaluate_model("Logistic Regression", y_test, y_pred_logreg)

### 2. K-Nearest Neighbors (KNN) ###
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train_scaled, y_train)
y_pred_knn = knn.predict(X_test_scaled)
evaluate_model("KNN", y_test, y_pred_knn)

### 3. Multi-Layer Perceptron (MLP - Yapay Sinir Ağı) ###
mlp = MLPClassifier(hidden_layer_sizes=(50, 30), max_iter=500, random_state=42)
mlp.fit(X_train_scaled, y_train)
y_pred_mlp = mlp.predict(X_test_scaled)
evaluate_model("MLP (Neural Network)", y_test, y_pred_mlp)

### 4. LightGBM ###
lgb_train = lgb.Dataset(X_train, label=y_train)
lgb_test = lgb.Dataset(X_test, label=y_test, reference=lgb_train)

params = {
    'objective': 'binary',
    'metric': 'binary_logloss',
    'verbose': -1
}

lgbm_model = lgb.train(params, lgb_train, num_boost_round=100)
y_pred_lgbm_proba = lgbm_model.predict(X_test)
y_pred_lgbm = [1 if prob > 0.5 else 0 for prob in y_pred_lgbm_proba]
evaluate_model("LightGBM", y_test, y_pred_lgbm)

"""## Modellerin Birbiriyle Karşılaştırma Tablosu"""

import pandas as pd
from IPython.display import display, HTML
data = {
    "Model": ["Logistic Regression", "KNN", "MLP (Neural Net)", "LightGBM"],
    "Accuracy": [0.81, 0.80, 0.80, 0.82],
    "Precision (1)": ["🟨 0.69", "🟧 0.55", "🟧 0.55", "🔥 0.67"],
    "Recall (1)": ["❌ 0.24", "🟡 0.36", "🟡 0.38", "🟡 0.36"],
    "F1-Score (1)": ["🔸 0.35", "🟠 0.43", "🟠 0.45", "✅ 0.47"],
    "False Negative (1)": ["~1000", "~845", "~820", "~844"],
    "Yorum": [
        "Sınıf 1'de başarısız, ödemeyenleri kaçırıyor.",
        "Temerrüt sınıfı daha iyi ama genel doğruluk düştü.",
        "Dengeli, F1 makul seviyede.",
        "En dengeli ve güçlü model. Tavsiye edilir."
    ]
}

df = pd.DataFrame(data)

# HTML formatında göster
display(HTML(df.to_html(escape=False, index=False)))

"""Yukarıdaki tablo, dört farklı sınıflandırma algoritmasının temerrüde düşen bireyleri (sınıf 1) tahmin etme performansını göstermektedir. Genel doğruluk oranı açısından en başarılı model %82 ile LightGBM olurken, onu %81 ile Logistic Regression, %80 ile KNN ve MLP takip etmektedir. Ancak sadece doğruluk değil, sınıf 1’i doğru tahmin etme başarısı (recall ve F1-score) bu proje açısından daha önemlidir. Bu açıdan bakıldığında Logistic Regression sınıf 1’i en az başarıyla ayırt etmiş (recall: 0.24, F1: 0.35), KNN ve MLP birbirine yakın sonuçlar üretmiş (F1: 0.43 ve 0.45), LightGBM ise en yüksek F1 puanına (0.47) ve dengeli precision-recall oranına ulaşmıştır. Sonuç olarak, temerrüde düşen bireyleri tespit etme açısından en başarılı modelin LightGBM olduğu, Logistic Regression'ın ise bu veri seti için yetersiz kaldığı görülmektedir.

## Lojistik Regresyon

🔴 Temerrüt (1):
Recall = 0.24 → Gerçek borcunu ödeyemeyenlerin sadece %24’ü doğru tespit edilmiş.
(Yani 1313 kişiden ≈ 1000’i gözden kaçmış. Bu çok yüksek bir False Negative.)
Precision = 0.69 → “Ödeyemedi” denenlerin %69’u gerçekten temerrütte.
→ Bu model, temerrüde düşenleri yakalamakta çok başarısız. Düşük recall, finansal riski artırır.

🟢 Ödemiş (0):
Recall = 0.97 → Borcunu ödeyenlerin %97’si doğru tanınmış.
Precision = 0.82 → “Ödemiş” denenlerin %82’si gerçekten ödemiş.
→ Ödemeleri iyi tahmin ediyor ama temerrütleri kaçırıyor.

## KNN

🔴 Temerrüt (1):
Recall = 0.36 → Gerçek borç ödemeyenlerin %36’sı yakalanabilmiş.
(Yani Logistic Regression’dan daha iyi.)
Precision = 0.55 → “Ödeyemedi” denilen kişilerin %55’i gerçekten ödeyememiş.
→ Hatalar hâlâ fazla ama en azından model bu grubu biraz daha iyi tanıyor.

🟢 Ödemiş (0):
Recall = 0.92 → Borcunu ödeyenlerin çoğu doğru sınıflandırılmış.
Precision = 0.84 → Doğruluğu da yüksek.
→ Bu model daha dengeli ama yine de temerrüt yakalama gücü zayıf.

## MLP

🔴 Temerrüt (1):
Recall = 0.38 → 1313 kişiden yaklaşık 500’ü doğru tahmin edilmiş.
Precision = 0.55 → “Temerrüt” tahminlerinin yarısından fazlası doğru.
→ KNN’ye göre biraz daha iyi sonuç vermiş. Riskli sınıf için daha güvenilir hale gelmiş.

🟢 Ödemiş (0):
Recall = 0.91 → Hatalar az, doğruluk yüksek.
→ Bu model genel olarak dengeli, ama hâlâ “temerrüt” sınıfını daha iyi tanıyacak iyileştirmeler gerek.

## LightGBM

🔴 Temerrüt (1):
Recall = 0.36 → 1313 kişinin yaklaşık 470’i doğru tespit edilmiş.
Precision = 0.67 → “Temerrüt” denenlerin %67’si gerçekten borcunu ödeyememiş.
→ Hem precision hem de F1-score açısından en güçlü model. Temerrüt sınıfı açısından en dengeli model.

🟢 Ödemiş (0):
Recall = 0.95 → Bu sınıfı yakalamakta çok iyi.
→ Genel başarı oranı yüksek ve hataların dağılımı en dengeli.

## Confusion Matrix Çizimi:
"""

# Modelleri yeniden tanımla ve dictionary içine al
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "KNN": KNeighborsClassifier(n_neighbors=5),
    "MLP": MLPClassifier(hidden_layer_sizes=(50, 30), max_iter=500, random_state=42),
    "LightGBM": lgb.LGBMClassifier()
}

plt.figure(figsize=(22, 5))
for i, (name, model) in enumerate(models.items()):
    # LightGBM dışındakiler için ölçeklenmiş veriyi kullanıyoruz
    if name == "LightGBM":
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
    else:
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)

    cm = confusion_matrix(y_test, y_pred)

    plt.subplot(1, 4, i + 1)
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=["Ödemiş (0)", "Temerrüt (1)"],
                yticklabels=["Ödemiş (0)", "Temerrüt (1)"])
    plt.title(f"{name} - Confusion Matrix")
    plt.xlabel("Tahmin Edilen")
    plt.ylabel("Gerçek")

plt.tight_layout()
plt.show()

"""🔷 1. Logistic Regression – Confusion Matrix
4549 kişi borcunu doğru şekilde “ödemiş” olarak tahmin etmiş.

138 kişiye yanlışlıkla “temerrüt” demiş → False Positive

1002 temerrütlü kişi “ödemiş” diye tahmin edilmiş → False Negative

Sınıf 1 (temerrüt) için kötü performans: çok fazla kaçırma var.
📌 Model, borcunu ödeyenleri çok iyi tanıyor ama temerrüde düşenleri neredeyse hiç yakalayamıyor.

🔷 2. KNN – Confusion Matrix
4302 doğru tahmin (ödemiş), 385 yanlış “temerrüt” demiş → FP

845 temerrütlü kişiyi kaçırmış, 468 kişiyi doğru tahmin etmiş → FN / TP
📌 LogReg’e göre daha dengeli. Temerrüde düşenleri yakalama oranı daha yüksek ama yine de eksik.

🔷 3. MLP (Neural Network) – Confusion Matrix
4286 kişi doğru ödemiş tahmini

401 kişiyi yanlışlıkla “temerrüt” diye tahmin etmiş

820 temerrüt kaçırılmış, 493 doğru yakalanmış
📌 KNN’ye yakın ama biraz daha dengeli çalışıyor. Temerrüt sınıfı daha iyi temsil ediliyor.

🔷 4. LightGBM – Confusion Matrix
4453 kişi doğru tahmin edilmiş (ödemiş), 234 kişi yanlışlıkla temerrüt denmiş

844 temerrütlü kişiyi kaçırmış, 469’unu doğru yakalamış
📌 En düşük false positive ve en yüksek precision + f1-score değerine sahip model. Temerrüt sınıfını yakalama oranı yüksek. Genel doğruluk da en iyi.
"""