# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q9u1G_2dTOKHSBZFFRJ1mhcfWRP5S4y0

Veri Setindeki AmaÃ§

Bu projede amaÃ§, bireylerin kredi kartÄ± temerrÃ¼t (Ã¶deyememe) durumlarÄ±nÄ± tahmin etmek iÃ§in Ã§eÅŸitli sÄ±nÄ±flandÄ±rma algoritmalarÄ±nÄ±n performanslarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rmaktÄ±r. KullanÄ±lacak algoritmalarÄ±n baÅŸarÄ±sÄ±; doÄŸruluk oranÄ± (accuracy), sÄ±nÄ±flandÄ±rma baÅŸarÄ±sÄ± ve karÄ±ÅŸÄ±klÄ±k matrisi (confusion matrix) gibi metrikler Ã¼zerinden deÄŸerlendirilecektir.



Veri Seti KaynaÄŸÄ±: Kaggle: Default of Credit Card Clients Dataset
SatÄ±r (GÃ¶zlem) SayÄ±sÄ±: 30.000
SÃ¼tun (Ã–zellik) SayÄ±sÄ±: 23
Hedef DeÄŸiÅŸken (Target): default.payment.next.month (0: TemerrÃ¼de dÃ¼ÅŸmedi, 1: TemerrÃ¼de dÃ¼ÅŸtÃ¼)



Veri Setinin AÃ§Ä±klamasÄ±
Bu veri seti, Tayvanâ€™daki bir bankaya ait kredi kartÄ± kullanÄ±cÄ±larÄ±nÄ±n geÃ§miÅŸ bilgilerini ve Ã¶deme alÄ±ÅŸkanlÄ±klarÄ±nÄ± iÃ§ermektedir. Banka, kullanÄ±cÄ±larÄ±n bir sonraki ay temerrÃ¼de dÃ¼ÅŸÃ¼p dÃ¼ÅŸmeyeceÄŸini tahmin etmek iÃ§in bu bilgileri kullanmaktadÄ±r. Bu sebeple veri seti, sÄ±nÄ±flandÄ±rma algoritmalarÄ±nÄ±n eÄŸitimi iÃ§in uygun bir Ã¶rnek teÅŸkil etmektedir.



Ã–zelliklerin DetaylÄ± AÃ§Ä±klamasÄ±:

LIMIT_BAL |	Kredi kartÄ± limiti (TWD biriminde)

SEX	| Cinsiyet (1=Erkek, 2=KadÄ±n)

EDUCATION	| EÄŸitim durumu (1=Mezuniyet, 2=Ãœniversite, 3=Lise, 4=DiÄŸer)

MARRIAGE |	Medeni durum (1=Evli, 2=Bekar, 3=DiÄŸer)

AGE |	YaÅŸ

PAY_0, PAY_2, ... |	Ã–nceki 6 aya ait Ã¶deme durumlarÄ± (geri Ã¶deme olup olmadÄ±ÄŸÄ±)

BILL_AMT1 ~ BILL_AMT6 | 6 ay boyunca fatura tutarlarÄ±

PAY_AMT1 ~ PAY_AMT6	| 6 ay boyunca yapÄ±lan Ã¶deme tutarlarÄ±

default.payment.next.month	| Hedef deÄŸiÅŸken â€“ KiÅŸi Ã¶demeyi yapmÄ±ÅŸ mÄ± (0) yoksa yapmamÄ±ÅŸ mÄ± (1)



Neden Bu Veri Seti SeÃ§ildi?
GerÃ§ek banka verileri iÃ§erdiÄŸi iÃ§in yÃ¼ksek doÄŸrulukla model eÄŸitimi yapÄ±labilir.

Ã–znitelik sayÄ±sÄ± yÃ¼ksek olduÄŸu iÃ§in veri Ã¶n iÅŸleme ve modelleme tekniklerinin uygulamasÄ± aÃ§Ä±sÄ±ndan zengindir.

Veri dengesi (sÄ±nÄ±flarÄ±n daÄŸÄ±lÄ±mÄ±), sÄ±nÄ±flandÄ±rma algoritmalarÄ±nÄ±n baÅŸarÄ±larÄ±nÄ± karÅŸÄ±laÅŸtÄ±rmak iÃ§in uygundur.

Kaggle'dan eriÅŸilebilir durumdadÄ±r.

## Veri Setini TanÄ±tma:
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
import lightgbm as lgb
from lightgbm import LGBMClassifier
from sklearn.metrics import classification_report, confusion_matrix


df = pd.read_csv("UCI_Credit_Card.csv")

# Veri setinin ilk 5 satÄ±rÄ±nÄ± gÃ¶rÃ¼ntÃ¼le
print("Veri setinin ilk 5 satÄ±rÄ±:")
print(df.head())

# Veri setinin boyutunu gÃ¶rÃ¼ntÃ¼le (satÄ±r ve sÃ¼tun sayÄ±sÄ±)
print("\nVeri setinin boyutu (satÄ±r, sÃ¼tun):")
print(df.shape)

# SÃ¼tun isimlerini listele
print("\nSÃ¼tun isimleri:")
print(df.columns.tolist())

# Hedef deÄŸiÅŸkenin (default.payment.next.month) sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶ster
print("\nHedef deÄŸiÅŸkenin sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:")
print(df["default.payment.next.month"].value_counts())

# Eksik deÄŸer olup olmadÄ±ÄŸÄ±nÄ± kontrol et
print("\nEksik deÄŸer sayÄ±sÄ± (her sÃ¼tun iÃ§in):")
print(df.isnull().sum())

# Temel istatistiksel Ã¶zetleri al (sayÄ±sal deÄŸiÅŸkenler iÃ§in)
print("\nTemel istatistiksel Ã¶zet:")
print(df.describe())

"""## Veri Setini Temizleme:"""

### 1. DENGESÄ°Z VERÄ° KONTROLÃœ ###
# Hedef deÄŸiÅŸkenin (default.payment.next.month) daÄŸÄ±lÄ±mÄ±na bakÄ±yoruz
print("\nSÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:")
print(df["default.payment.next.month"].value_counts())

# SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶rselleÅŸtir
sns.countplot(x="default.payment.next.month", data=df)
plt.title("Hedef DeÄŸiÅŸkenin (default.payment.next.month) SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±")
plt.xlabel("TemerrÃ¼t Durumu (0=Yok, 1=Var)")
plt.ylabel("KiÅŸi SayÄ±sÄ±")
plt.show()


### 2. OUTLIER (AYKIRI DEÄER) KONTROLÃœ ###
# SayÄ±sal sÃ¼tunlar Ã¼zerinden boxplot Ã§izerek aykÄ±rÄ± deÄŸerleri gÃ¶relim
sayisal_sutunlar = df.select_dtypes(include=["int64", "float64"]).columns

# Her Ã¶zellik iÃ§in boxplot (ilk 6'sÄ± Ã¶rnek olarak Ã§izilir)
plt.figure(figsize=(15, 10))
for i, col in enumerate(sayisal_sutunlar[:6]):
    plt.subplot(2, 3, i+1)
    sns.boxplot(y=df[col])
    plt.title(f"{col} Boxplot")
plt.tight_layout()
plt.show()

"""Hedef deÄŸiÅŸken olan default.payment.next.month deÄŸiÅŸkenine ait sÄ±nÄ±f daÄŸÄ±lÄ±mÄ± grafiÄŸi incelendiÄŸinde, temerrÃ¼de dÃ¼ÅŸmeyen (0) bireylerin sayÄ±sÄ±nÄ±n 23.364, temerrÃ¼de dÃ¼ÅŸen (1) bireylerin sayÄ±sÄ±nÄ±n ise 6.636 olduÄŸu gÃ¶rÃ¼lmektedir. Bu durum veri setinde bir miktar sÄ±nÄ±f dengesizliÄŸi olduÄŸunu gÃ¶stermektedir. Yani, borcunu Ã¶demeyen bireylerin sayÄ±sÄ± Ã¶deyenlere gÃ¶re daha azdÄ±r. Ancak bu fark Ã§ok uÃ§ dÃ¼zeyde olmadÄ±ÄŸÄ± iÃ§in sÄ±nÄ±flandÄ±rma algoritmalarÄ± bu daÄŸÄ±lÄ±mla baÅŸ edebilir. Yine de modelleme sÃ¼recinde sÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ± dikkatli ayarlanmalÄ± veya gerekiyorsa SMOTE gibi veri dengeleme yÃ¶ntemleri kullanÄ±lmalÄ±dÄ±r.

LIMIT_BAL deÄŸiÅŸkenine ait boxplot incelendiÄŸinde, kredi kartÄ± limitleri arasÄ±nda bÃ¼yÃ¼k farklÄ±lÄ±klar olduÄŸu ve Ã¼st sÄ±nÄ±rda birÃ§ok aykÄ±rÄ± deÄŸerin bulunduÄŸu gÃ¶zlemlenmektedir. Ã–zellikle bazÄ± bireylerin limitlerinin 1 milyon TWDâ€™ye kadar Ã§Ä±kmasÄ±, bu kiÅŸilerin normal popÃ¼lasyondan farklÄ± finansal profillere sahip olduklarÄ±nÄ± gÃ¶stermektedir. Bu tarz uÃ§ deÄŸerler finansal veri setlerinde olaÄŸan kabul edilebilir ve doÄŸrudan veri dÄ±ÅŸÄ± bÄ±rakÄ±lmasÄ± yerine Ã¶lÃ§eklendirme (scaling) ya da log dÃ¶nÃ¼ÅŸÃ¼mÃ¼ gibi yÃ¶ntemlerle modele dahil edilmesi Ã¶nerilir.

AGE deÄŸiÅŸkeni iÃ§in Ã§izilen boxplotâ€™ta da aykÄ±rÄ± deÄŸerler mevcuttur. YaÅŸ deÄŸeri 60â€™Ä±n Ã¼zerine Ã§Ä±kan bireylerin kutunun dÄ±ÅŸÄ±nda konumlandÄ±ÄŸÄ± ve istatistiksel olarak aykÄ±rÄ± kabul edildiÄŸi gÃ¶rÃ¼lmektedir. Ancak yaÅŸ verisi doÄŸasÄ± gereÄŸi geniÅŸ bir aralÄ±kta daÄŸÄ±ldÄ±ÄŸÄ± iÃ§in, bu deÄŸerler gerÃ§ek bireyleri temsil ettiÄŸinden silinmesi yerine dikkatli ÅŸekilde modele dahil edilmelidir. Genel olarak yaÅŸ deÄŸiÅŸkeni, kredi Ã¶deme davranÄ±ÅŸlarÄ±yla doÄŸrudan iliÅŸkili olabileceÄŸi iÃ§in, analizlerde Ã¶nemli bir rol oynayabilir.

EDUCATION deÄŸiÅŸkenine ait boxplot grafiÄŸinde ise veri sÃ¶zlÃ¼ÄŸÃ¼nde tanÄ±mlÄ± olmayan 0, 5 ve 6 gibi deÄŸerlerin bulunduÄŸu gÃ¶rÃ¼lmektedir. Bu da veri setinde bazÄ± kodlama hatalarÄ± ya da eksik bilgi kategorilerinin olduÄŸunu dÃ¼ÅŸÃ¼ndÃ¼rmektedir. Normalde eÄŸitim dÃ¼zeyleri 1 (lisansÃ¼stÃ¼), 2 (Ã¼niversite), 3 (lise) ve 4 (diÄŸer) gibi tanÄ±mlanmÄ±ÅŸken, bu deÄŸerlerin varlÄ±ÄŸÄ± veri Ã¶n iÅŸleme aÅŸamasÄ±nda ele alÄ±nmalÄ±dÄ±r. Bu tÃ¼r veriler, "bilinmiyor" ya da "diÄŸer" ÅŸeklinde yeniden sÄ±nÄ±flandÄ±rÄ±larak dÃ¼zeltilmelidir.

MARRIAGE deÄŸiÅŸkenine ait boxplot grafiÄŸi de benzer bir sorunu yansÄ±tmaktadÄ±r. Normalde evli (1), bekar (2) ve diÄŸer (3) gibi deÄŸerler iÃ§ermesi gereken bu sÃ¼tunda 0 deÄŸeri de yer almaktadÄ±r. 0 deÄŸeri bÃ¼yÃ¼k ihtimalle eksik veya yanlÄ±ÅŸ veri giriÅŸinden kaynaklanmaktadÄ±r. Bu deÄŸerler de veri Ã¶n iÅŸleme aÅŸamasÄ±nda uygun ÅŸekilde yeniden sÄ±nÄ±flandÄ±rÄ±lmalÄ± ya da analiz dÄ±ÅŸÄ±nda bÄ±rakÄ±lmalÄ±dÄ±r. Ã‡Ã¼nkÃ¼ kategorik deÄŸiÅŸkenlerde tanÄ±msÄ±z deÄŸerler modelin performansÄ±nÄ± olumsuz etkileyebilir.

Son olarak, SEX ve ID deÄŸiÅŸkenlerine ait boxplot'larda teknik olarak aykÄ±rÄ± deÄŸer gÃ¶rÃ¼nmese de bu sÃ¼tunlar modelleme aÃ§Ä±sÄ±ndan dikkatli deÄŸerlendirilmelidir. SEX sÃ¼tunu zaten sadece 1 ve 2 deÄŸerleri (erkek/kadÄ±n) iÃ§erdiÄŸinden dolayÄ± boxplot grafik olarak anlamlÄ± bir Ã§Ä±karÄ±m sunmaz. ID deÄŸiÅŸkeni ise her birey iÃ§in benzersiz bir numara olduÄŸu iÃ§in modelde kullanÄ±lmamalÄ±dÄ±r. Bu tÃ¼r tanÄ±mlayÄ±cÄ± alanlar sadece indeksleme amacÄ±yla kullanÄ±lÄ±r ve doÄŸrudan analizde yer almaz.
"""

# ID sÃ¼tunu modellemeye dahil edilmemeli, bu yÃ¼zden kaldÄ±ralÄ±m
df.drop("ID", axis=1, inplace=True)

# BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) ve hedef deÄŸiÅŸken (y) olarak ayÄ±r
X = df.drop("default.payment.next.month", axis=1)
y = df["default.payment.next.month"]

# Veriyi eÄŸitim (%80) ve test (%20) olarak ayÄ±r
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# SayÄ±sal verileri Ã¶lÃ§eklendirme (Ã¶zellikle KNN ve MLP iÃ§in Ã¶nemli)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# SonuÃ§larÄ± tutmak iÃ§in fonksiyon
def evaluate_model(name, y_true, y_pred):
    print(f"\n=== {name} ===")
    print("Confusion Matrix:")
    print(confusion_matrix(y_true, y_pred))
    print("\nClassification Report:")
    print(classification_report(y_true, y_pred))

### 1. Logistic Regression ###
logreg = LogisticRegression(max_iter=1000)
logreg.fit(X_train_scaled, y_train)
y_pred_logreg = logreg.predict(X_test_scaled)
evaluate_model("Logistic Regression", y_test, y_pred_logreg)

### 2. K-Nearest Neighbors (KNN) ###
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train_scaled, y_train)
y_pred_knn = knn.predict(X_test_scaled)
evaluate_model("KNN", y_test, y_pred_knn)

### 3. Multi-Layer Perceptron (MLP - Yapay Sinir AÄŸÄ±) ###
mlp = MLPClassifier(hidden_layer_sizes=(50, 30), max_iter=500, random_state=42)
mlp.fit(X_train_scaled, y_train)
y_pred_mlp = mlp.predict(X_test_scaled)
evaluate_model("MLP (Neural Network)", y_test, y_pred_mlp)

### 4. LightGBM ###
lgb_train = lgb.Dataset(X_train, label=y_train)
lgb_test = lgb.Dataset(X_test, label=y_test, reference=lgb_train)

params = {
    'objective': 'binary',
    'metric': 'binary_logloss',
    'verbose': -1
}

lgbm_model = lgb.train(params, lgb_train, num_boost_round=100)
y_pred_lgbm_proba = lgbm_model.predict(X_test)
y_pred_lgbm = [1 if prob > 0.5 else 0 for prob in y_pred_lgbm_proba]
evaluate_model("LightGBM", y_test, y_pred_lgbm)

"""## Modellerin Birbiriyle KarÅŸÄ±laÅŸtÄ±rma Tablosu"""

import pandas as pd
from IPython.display import display, HTML
data = {
    "Model": ["Logistic Regression", "KNN", "MLP (Neural Net)", "LightGBM"],
    "Accuracy": [0.81, 0.80, 0.80, 0.82],
    "Precision (1)": ["ğŸŸ¨ 0.69", "ğŸŸ§ 0.55", "ğŸŸ§ 0.55", "ğŸ”¥ 0.67"],
    "Recall (1)": ["âŒ 0.24", "ğŸŸ¡ 0.36", "ğŸŸ¡ 0.38", "ğŸŸ¡ 0.36"],
    "F1-Score (1)": ["ğŸ”¸ 0.35", "ğŸŸ  0.43", "ğŸŸ  0.45", "âœ… 0.47"],
    "False Negative (1)": ["~1000", "~845", "~820", "~844"],
    "Yorum": [
        "SÄ±nÄ±f 1'de baÅŸarÄ±sÄ±z, Ã¶demeyenleri kaÃ§Ä±rÄ±yor.",
        "TemerrÃ¼t sÄ±nÄ±fÄ± daha iyi ama genel doÄŸruluk dÃ¼ÅŸtÃ¼.",
        "Dengeli, F1 makul seviyede.",
        "En dengeli ve gÃ¼Ã§lÃ¼ model. Tavsiye edilir."
    ]
}

df = pd.DataFrame(data)

# HTML formatÄ±nda gÃ¶ster
display(HTML(df.to_html(escape=False, index=False)))

"""YukarÄ±daki tablo, dÃ¶rt farklÄ± sÄ±nÄ±flandÄ±rma algoritmasÄ±nÄ±n temerrÃ¼de dÃ¼ÅŸen bireyleri (sÄ±nÄ±f 1) tahmin etme performansÄ±nÄ± gÃ¶stermektedir. Genel doÄŸruluk oranÄ± aÃ§Ä±sÄ±ndan en baÅŸarÄ±lÄ± model %82 ile LightGBM olurken, onu %81 ile Logistic Regression, %80 ile KNN ve MLP takip etmektedir. Ancak sadece doÄŸruluk deÄŸil, sÄ±nÄ±f 1â€™i doÄŸru tahmin etme baÅŸarÄ±sÄ± (recall ve F1-score) bu proje aÃ§Ä±sÄ±ndan daha Ã¶nemlidir. Bu aÃ§Ä±dan bakÄ±ldÄ±ÄŸÄ±nda Logistic Regression sÄ±nÄ±f 1â€™i en az baÅŸarÄ±yla ayÄ±rt etmiÅŸ (recall: 0.24, F1: 0.35), KNN ve MLP birbirine yakÄ±n sonuÃ§lar Ã¼retmiÅŸ (F1: 0.43 ve 0.45), LightGBM ise en yÃ¼ksek F1 puanÄ±na (0.47) ve dengeli precision-recall oranÄ±na ulaÅŸmÄ±ÅŸtÄ±r. SonuÃ§ olarak, temerrÃ¼de dÃ¼ÅŸen bireyleri tespit etme aÃ§Ä±sÄ±ndan en baÅŸarÄ±lÄ± modelin LightGBM olduÄŸu, Logistic Regression'Ä±n ise bu veri seti iÃ§in yetersiz kaldÄ±ÄŸÄ± gÃ¶rÃ¼lmektedir.

## Lojistik Regresyon

ğŸ”´ TemerrÃ¼t (1):
Recall = 0.24 â†’ GerÃ§ek borcunu Ã¶deyemeyenlerin sadece %24â€™Ã¼ doÄŸru tespit edilmiÅŸ.
(Yani 1313 kiÅŸiden â‰ˆ 1000â€™i gÃ¶zden kaÃ§mÄ±ÅŸ. Bu Ã§ok yÃ¼ksek bir False Negative.)
Precision = 0.69 â†’ â€œÃ–deyemediâ€ denenlerin %69â€™u gerÃ§ekten temerrÃ¼tte.
â†’ Bu model, temerrÃ¼de dÃ¼ÅŸenleri yakalamakta Ã§ok baÅŸarÄ±sÄ±z. DÃ¼ÅŸÃ¼k recall, finansal riski artÄ±rÄ±r.

ğŸŸ¢ Ã–demiÅŸ (0):
Recall = 0.97 â†’ Borcunu Ã¶deyenlerin %97â€™si doÄŸru tanÄ±nmÄ±ÅŸ.
Precision = 0.82 â†’ â€œÃ–demiÅŸâ€ denenlerin %82â€™si gerÃ§ekten Ã¶demiÅŸ.
â†’ Ã–demeleri iyi tahmin ediyor ama temerrÃ¼tleri kaÃ§Ä±rÄ±yor.

## KNN

ğŸ”´ TemerrÃ¼t (1):
Recall = 0.36 â†’ GerÃ§ek borÃ§ Ã¶demeyenlerin %36â€™sÄ± yakalanabilmiÅŸ.
(Yani Logistic Regressionâ€™dan daha iyi.)
Precision = 0.55 â†’ â€œÃ–deyemediâ€ denilen kiÅŸilerin %55â€™i gerÃ§ekten Ã¶deyememiÅŸ.
â†’ Hatalar hÃ¢lÃ¢ fazla ama en azÄ±ndan model bu grubu biraz daha iyi tanÄ±yor.

ğŸŸ¢ Ã–demiÅŸ (0):
Recall = 0.92 â†’ Borcunu Ã¶deyenlerin Ã§oÄŸu doÄŸru sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ.
Precision = 0.84 â†’ DoÄŸruluÄŸu da yÃ¼ksek.
â†’ Bu model daha dengeli ama yine de temerrÃ¼t yakalama gÃ¼cÃ¼ zayÄ±f.

## MLP

ğŸ”´ TemerrÃ¼t (1):
Recall = 0.38 â†’ 1313 kiÅŸiden yaklaÅŸÄ±k 500â€™Ã¼ doÄŸru tahmin edilmiÅŸ.
Precision = 0.55 â†’ â€œTemerrÃ¼tâ€ tahminlerinin yarÄ±sÄ±ndan fazlasÄ± doÄŸru.
â†’ KNNâ€™ye gÃ¶re biraz daha iyi sonuÃ§ vermiÅŸ. Riskli sÄ±nÄ±f iÃ§in daha gÃ¼venilir hale gelmiÅŸ.

ğŸŸ¢ Ã–demiÅŸ (0):
Recall = 0.91 â†’ Hatalar az, doÄŸruluk yÃ¼ksek.
â†’ Bu model genel olarak dengeli, ama hÃ¢lÃ¢ â€œtemerrÃ¼tâ€ sÄ±nÄ±fÄ±nÄ± daha iyi tanÄ±yacak iyileÅŸtirmeler gerek.

## LightGBM

ğŸ”´ TemerrÃ¼t (1):
Recall = 0.36 â†’ 1313 kiÅŸinin yaklaÅŸÄ±k 470â€™i doÄŸru tespit edilmiÅŸ.
Precision = 0.67 â†’ â€œTemerrÃ¼tâ€ denenlerin %67â€™si gerÃ§ekten borcunu Ã¶deyememiÅŸ.
â†’ Hem precision hem de F1-score aÃ§Ä±sÄ±ndan en gÃ¼Ã§lÃ¼ model. TemerrÃ¼t sÄ±nÄ±fÄ± aÃ§Ä±sÄ±ndan en dengeli model.

ğŸŸ¢ Ã–demiÅŸ (0):
Recall = 0.95 â†’ Bu sÄ±nÄ±fÄ± yakalamakta Ã§ok iyi.
â†’ Genel baÅŸarÄ± oranÄ± yÃ¼ksek ve hatalarÄ±n daÄŸÄ±lÄ±mÄ± en dengeli.

## Confusion Matrix Ã‡izimi:
"""

# Modelleri yeniden tanÄ±mla ve dictionary iÃ§ine al
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "KNN": KNeighborsClassifier(n_neighbors=5),
    "MLP": MLPClassifier(hidden_layer_sizes=(50, 30), max_iter=500, random_state=42),
    "LightGBM": lgb.LGBMClassifier()
}

plt.figure(figsize=(22, 5))
for i, (name, model) in enumerate(models.items()):
    # LightGBM dÄ±ÅŸÄ±ndakiler iÃ§in Ã¶lÃ§eklenmiÅŸ veriyi kullanÄ±yoruz
    if name == "LightGBM":
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
    else:
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)

    cm = confusion_matrix(y_test, y_pred)

    plt.subplot(1, 4, i + 1)
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=["Ã–demiÅŸ (0)", "TemerrÃ¼t (1)"],
                yticklabels=["Ã–demiÅŸ (0)", "TemerrÃ¼t (1)"])
    plt.title(f"{name} - Confusion Matrix")
    plt.xlabel("Tahmin Edilen")
    plt.ylabel("GerÃ§ek")

plt.tight_layout()
plt.show()

"""ğŸ”· 1. Logistic Regression â€“ Confusion Matrix
4549 kiÅŸi borcunu doÄŸru ÅŸekilde â€œÃ¶demiÅŸâ€ olarak tahmin etmiÅŸ.

138 kiÅŸiye yanlÄ±ÅŸlÄ±kla â€œtemerrÃ¼tâ€ demiÅŸ â†’ False Positive

1002 temerrÃ¼tlÃ¼ kiÅŸi â€œÃ¶demiÅŸâ€ diye tahmin edilmiÅŸ â†’ False Negative

SÄ±nÄ±f 1 (temerrÃ¼t) iÃ§in kÃ¶tÃ¼ performans: Ã§ok fazla kaÃ§Ä±rma var.
ğŸ“Œ Model, borcunu Ã¶deyenleri Ã§ok iyi tanÄ±yor ama temerrÃ¼de dÃ¼ÅŸenleri neredeyse hiÃ§ yakalayamÄ±yor.

ğŸ”· 2. KNN â€“ Confusion Matrix
4302 doÄŸru tahmin (Ã¶demiÅŸ), 385 yanlÄ±ÅŸ â€œtemerrÃ¼tâ€ demiÅŸ â†’ FP

845 temerrÃ¼tlÃ¼ kiÅŸiyi kaÃ§Ä±rmÄ±ÅŸ, 468 kiÅŸiyi doÄŸru tahmin etmiÅŸ â†’ FN / TP
ğŸ“Œ LogRegâ€™e gÃ¶re daha dengeli. TemerrÃ¼de dÃ¼ÅŸenleri yakalama oranÄ± daha yÃ¼ksek ama yine de eksik.

ğŸ”· 3. MLP (Neural Network) â€“ Confusion Matrix
4286 kiÅŸi doÄŸru Ã¶demiÅŸ tahmini

401 kiÅŸiyi yanlÄ±ÅŸlÄ±kla â€œtemerrÃ¼tâ€ diye tahmin etmiÅŸ

820 temerrÃ¼t kaÃ§Ä±rÄ±lmÄ±ÅŸ, 493 doÄŸru yakalanmÄ±ÅŸ
ğŸ“Œ KNNâ€™ye yakÄ±n ama biraz daha dengeli Ã§alÄ±ÅŸÄ±yor. TemerrÃ¼t sÄ±nÄ±fÄ± daha iyi temsil ediliyor.

ğŸ”· 4. LightGBM â€“ Confusion Matrix
4453 kiÅŸi doÄŸru tahmin edilmiÅŸ (Ã¶demiÅŸ), 234 kiÅŸi yanlÄ±ÅŸlÄ±kla temerrÃ¼t denmiÅŸ

844 temerrÃ¼tlÃ¼ kiÅŸiyi kaÃ§Ä±rmÄ±ÅŸ, 469â€™unu doÄŸru yakalamÄ±ÅŸ
ğŸ“Œ En dÃ¼ÅŸÃ¼k false positive ve en yÃ¼ksek precision + f1-score deÄŸerine sahip model. TemerrÃ¼t sÄ±nÄ±fÄ±nÄ± yakalama oranÄ± yÃ¼ksek. Genel doÄŸruluk da en iyi.
"""